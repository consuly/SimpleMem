<div align="center">

<img alt="simplemem_logo" src="https://github.com/user-attachments/assets/6ea54ad1-e007-442c-99d7-1174b10d1fec" width="450">

<div align="center">

## LLM 에이전트를 위한 효율적인 평생 기억 시스템

<small>의미적 무손실 압축을 통해 장기 기억의 저장, 압축 및 검색을 실현합니다. Claude, Cursor, LM Studio 등 다양한 플랫폼을 지원합니다.</small>

</div>

<p><b>MCP 또는 Python 통합을 지원하는 모든 AI 플랫폼에서 작동</b></p>

<table>
<tr>

<td align="center" width="100">
  <a href="https://www.anthropic.com/claude">
    <img src="https://cdn.simpleicons.org/claude/D97757" width="48" height="48" alt="Claude Desktop" />
  </a><br/>
  <sub>
    <a href="https://www.anthropic.com/claude"><b>Claude Desktop</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://cursor.com">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://cdn.simpleicons.org/cursor/FFFFFF">
      <img src="https://cdn.simpleicons.org/cursor/000000" width="48" height="48" alt="Cursor" />
    </picture>
  </a><br/>
  <sub>
    <a href="https://cursor.com"><b>Cursor</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://lmstudio.ai">
    <img src="https://github.com/lmstudio-ai.png?size=200" width="48" height="48" alt="LM Studio" />
  </a><br/>
  <sub>
    <a href="https://lmstudio.ai"><b>LM Studio</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://cherry-ai.com">
    <img src="https://github.com/CherryHQ.png?size=200" width="48" height="48" alt="Cherry Studio" />
  </a><br/>
  <sub>
    <a href="https://cherry-ai.com"><b>Cherry Studio</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://pypi.org/project/simplemem/">
    <img src="https://cdn.simpleicons.org/pypi/3775A9" width="48" height="48" alt="PyPI" />
  </a><br/>
  <sub>
    <a href="https://pypi.org/project/simplemem/"><b>PyPI 패키지</b></a>
  </sub>
</td>

<td align="center" width="100">
  <sub><b>+ 모든 MCP<br/>클라이언트</b></sub>
</td>

</tr>
</table>

<div align="center">

<br/>

[🇨🇳 中文](./README.zh-CN.md) •
[🇯🇵 日本語](./README.ja.md) •
[🇰🇷 **한국어**](./README.ko.md) •
[🇪🇸 Español](./README.es.md) •
[🇫🇷 Français](./README.fr.md) •
[🇩🇪 Deutsch](./README.de.md) •
[🇧🇷 Português](./README.pt-br.md)<br/>
[🇷🇺 Русский](./README.ru.md) •
[🇸🇦 العربية](./README.ar.md) •
[🇮🇹 Italiano](./README.it.md) •
[🇻🇳 Tiếng Việt](./README.vi.md) •
[🇹🇷 Türkçe](./README.tr.md)

<br/>

[![Project Page](https://img.shields.io/badge/🎬_인터랙티브_데모-웹사이트_방문-FF6B6B?style=for-the-badge&labelColor=FF6B6B&color=4ECDC4&logoColor=white)](https://aiming-lab.github.io/SimpleMem-Page)

<p align="center">
  <a href="https://arxiv.org/abs/2601.02553"><img src="https://img.shields.io/badge/arXiv-2601.02553-b31b1b?style=flat&labelColor=555" alt="arXiv"></a>
  <a href="https://github.com/aiming-lab/SimpleMem"><img src="https://img.shields.io/badge/github-SimpleMem-181717?style=flat&labelColor=555&logo=github&logoColor=white" alt="GitHub"></a>
  <a href="../../LICENSE"><img src="https://img.shields.io/github/license/aiming-lab/SimpleMem?style=flat&label=license&labelColor=555&color=2EA44F" alt="License"></a>
  <a href="https://github.com/aiming-lab/SimpleMem/pulls"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen?style=flat&labelColor=555" alt="PRs Welcome"></a>
  <br/>
  <a href="https://pypi.org/project/simplemem/"><img src="https://img.shields.io/pypi/v/simplemem?style=flat&label=pypi&labelColor=555&color=3775A9&logo=pypi&logoColor=white" alt="PyPI"></a>
  <a href="https://pypi.org/project/simplemem/"><img src="https://img.shields.io/pypi/pyversions/simplemem?style=flat&label=python&labelColor=555&color=3775A9&logo=python&logoColor=white" alt="Python"></a>
  <a href="https://mcp.simplemem.cloud"><img src="https://img.shields.io/badge/MCP-mcp.simplemem.cloud-14B8A6?style=flat&labelColor=555" alt="MCP Server"></a>
  <a href="https://github.com/aiming-lab/SimpleMem"><img src="https://img.shields.io/badge/Claude_Skills-supported-FFB000?style=flat&labelColor=555" alt="Claude Skills"></a>
  <br/>
  <a href="https://discord.gg/KA2zC32M"><img src="https://img.shields.io/badge/Discord-채팅_참여-5865F2?style=flat&labelColor=555&logo=discord&logoColor=white" alt="Discord"></a>
  <a href="../../fig/wechat_logo3.JPG"><img src="https://img.shields.io/badge/WeChat-그룹-07C160?style=flat&labelColor=555&logo=wechat&logoColor=white" alt="WeChat"></a>
</p>

<br/>

[개요](#-개요) • [빠른 시작](#-빠른-시작) • [MCP 서버](#-mcp-서버) • [평가](#-평가) • [인용](#-인용)

</div>

</div>

<br/>

## 🔥 최신 소식

- **[01/20/2026]** **SimpleMem이 PyPI에 출시되었습니다!** 📦 `pip install simplemem`으로 직접 설치할 수 있습니다. [패키지 사용 가이드 보기 →](../PACKAGE_USAGE.md)
- **[01/19/2026]** **SimpleMem Skill에 로컬 메모리 스토리지 추가!** 💾 Claude Skills 내에서 로컬 메모리 저장 및 관리를 지원합니다.
- **[01/18/2026]** **SimpleMem이 Claude Skills를 지원합니다!** 🚀 claude.ai에서 대화 간 장기 기억을 실현하세요. [mcp.simplemem.cloud](https://mcp.simplemem.cloud)에서 등록하고 토큰을 설정한 후 스킬을 가져오세요!
- **[01/14/2026]** **SimpleMem MCP 서버 정식 출시 및 오픈 소스 공개!** 🎉 [mcp.simplemem.cloud](https://mcp.simplemem.cloud)에서 클라우드 메모리 서비스를 이용할 수 있습니다. **Streamable HTTP** MCP 프로토콜을 통해 LM Studio, Cherry Studio, Cursor, Claude Desktop과 통합됩니다. [MCP 문서 보기 →](../../MCP/README.md)
- **[01/08/2026]** 🔥 [Discord](https://discord.gg/KA2zC32M)와 [WeChat 그룹](../../fig/wechat_logo3.JPG)에 참여하여 함께 협업하고 아이디어를 교환하세요!
- **[01/05/2026]** SimpleMem 논문이 [arXiv](https://arxiv.org/abs/2601.02553)에 공개되었습니다!

---

## 📑 목차

- [🌟 개요](#-개요)
- [🎯 주요 기여](#-주요-기여)
- [🚀 성능 하이라이트](#-성능-하이라이트)
- [📦 설치](#-설치)
- [⚡ 빠른 시작](#-빠른-시작)
- [🔌 MCP 서버](#-mcp-서버)
- [📊 평가](#-평가)
- [📝 인용](#-인용)
- [📄 라이선스](#-라이선스)
- [🙏 감사의 말](#-감사의-말)

---

## 🌟 개요

<div align="center">
<img src="../../fig/Fig_tradeoff.png" alt="성능 대 효율성 트레이드오프" width="900"/>

*SimpleMem은 최소한의 토큰 비용(약 550)으로 최고의 F1 점수(43.24%)를 달성하여 이상적인 왼쪽 상단 위치를 차지합니다.*
</div>

**SimpleMem**은 **의미적 무손실 압축**에 기반한 효율적인 메모리 프레임워크로, **LLM 에이전트의 효율적인 장기 기억**이라는 근본적인 과제를 해결합니다. 중복 컨텍스트를 수동적으로 축적하거나 비용이 높은 반복적 추론 루프에 의존하는 기존 시스템과 달리, SimpleMem은 3단계 파이프라인을 통해 **정보 밀도**와 **토큰 활용률**을 극대화합니다:

<table>
<tr>
<td width="33%" align="center">

### 🔍 단계 1
**의미적 구조화 압축**

비구조화 상호작용을 컴팩트한 다중 뷰 인덱스 메모리 유닛으로 증류

</td>
<td width="33%" align="center">

### 🗂️ 단계 2
**온라인 의미 합성**

세션 내 프로세스로 관련 컨텍스트를 통합 추상 표현으로 즉시 통합하여 중복 제거

</td>
<td width="33%" align="center">

### 🎯 단계 3
**의도 인식 검색 계획**

검색 의도를 추론하여 검색 범위를 동적으로 결정하고 효율적으로 정확한 컨텍스트를 구성

</td>
</tr>
</table>

<div align="center">
<img src="../../fig/Fig_framework.png" alt="SimpleMem 프레임워크" width="900"/>

*SimpleMem 아키텍처: (1) 의미적 구조화 압축이 저효용 대화를 필터링하고 정보 윈도우를 컴팩트하고 컨텍스트 독립적인 메모리 유닛으로 변환. (2) 온라인 의미 합성이 쓰기 단계에서 관련 프래그먼트를 통합하여 컴팩트하고 일관된 메모리 토폴로지를 유지. (3) 의도 인식 검색 계획이 검색 의도를 추론하여 검색 범위와 쿼리 형태를 적응시키고 병렬 다중 뷰 검색과 토큰 효율적 컨텍스트 구성을 실현.*
</div>

---

### 🏆 성능 비교

<div align="center">

**속도 비교 데모**

<video src="https://github.com/aiming-lab/SimpleMem/raw/main/fig/simplemem-new.mp4" controls width="900"></video>

*SimpleMem vs. 베이스라인: 실시간 속도 비교 시연*

</div>

<div align="center">

**LoCoMo-10 벤치마크 결과 (GPT-4.1-mini)**

| 모델 | ⏱️ 구축 시간 | 🔎 검색 시간 | ⚡ 총 시간 | 🎯 평균 F1 |
|:------|:--------------------:|:-----------------:|:-------------:|:-------------:|
| A-Mem | 5140.5s | 796.7s | 5937.2s | 32.58% |
| LightMem | 97.8s | 577.1s | 675.9s | 24.63% |
| Mem0 | 1350.9s | 583.4s | 1934.3s | 34.20% |
| **SimpleMem** ⭐ | **92.6s** | **388.3s** | **480.9s** | **43.24%** |

</div>

> **💡 핵심 장점:**
> - 🏆 **최고 F1 점수**: 43.24% (Mem0 대비 +26.4%, LightMem 대비 +75.6%)
> - ⚡ **최고 검색 속도**: 388.3s (LightMem보다 32.7% 빠름, Mem0보다 51.3% 빠름)
> - 🚀 **최고 종합 속도**: 총 처리 시간 480.9s (A-Mem의 12.5배 빠름)

---

## 🎯 주요 기여

### 1️⃣ 의미적 구조화 압축

SimpleMem은 LLM 생성 프로세스에 통합된 **암묵적 의미 밀도 게이팅** 메커니즘을 적용하여 중복 상호작용 콘텐츠를 필터링합니다. 시스템은 원시 대화 스트림을 **컴팩트한 메모리 유닛**(공참조가 해결되고 절대 타임스탬프가 부여된 자체 완결적 사실)으로 재구성합니다. 각 유닛은 유연한 검색을 위해 세 가지 보완적 표현으로 인덱싱됩니다:

<div align="center">

| 🔍 레이어 | 📊 유형 | 🎯 목적 | 🛠️ 구현 |
|---------|---------|------------|-------------------|
| **의미적** | 밀집 | 개념적 유사성 | 벡터 임베딩 (1024차원) |
| **어휘적** | 희소 | 정확한 용어 매칭 | BM25 스타일 키워드 인덱스 |
| **기호적** | 메타데이터 | 구조화 필터링 | 타임스탬프, 엔티티, 인물 |

</div>

**✨ 변환 예시:**
```diff
- 입력:  "그가 내일 오후 2시에 Bob을 만날 거야"  [❌ 상대적, 모호함]
+ 출력: "Alice가 Starbucks에서 2025-11-16T14:00:00에 Bob을 만남"  [✅ 절대적, 원자적]
```

---

### 2️⃣ 온라인 의미 합성

비동기 백그라운드 유지보수에 의존하는 기존 시스템과 달리, SimpleMem은 **쓰기 단계에서 즉석으로 합성**을 수행합니다. 관련 메모리 유닛은 현재 세션 범위 내에서 더 높은 수준의 추상 표현으로 합성되어, 반복적이거나 구조적으로 유사한 경험을 **즉시 노이즈 제거 및 압축**할 수 있습니다.

**✨ 합성 예시:**
```diff
- 프래그먼트 1: "사용자가 커피를 원함"
- 프래그먼트 2: "사용자가 오트 밀크를 선호함"
- 프래그먼트 3: "사용자가 뜨거운 것을 좋아함"
+ 통합 결과: "사용자가 오트 밀크 핫 커피를 선호함"
```

이러한 능동적 합성을 통해 메모리 토폴로지가 컴팩트하게 유지되고 중복 단편화가 방지됩니다.

---

### 3️⃣ 의도 인식 검색 계획

고정 깊이 검색 대신, SimpleMem은 LLM의 추론 능력을 활용하여 **포괄적인 검색 계획**을 생성합니다. 쿼리가 주어지면 계획 모듈이 **잠재적 검색 의도**를 추론하여 검색 범위와 깊이를 동적으로 결정합니다:

$$\{ q_{\text{sem}}, q_{\text{lex}}, q_{\text{sym}}, d \} \sim \mathcal{P}(q, H)$$

시스템은 의미적, 어휘적, 기호적 인덱스에 걸쳐 **병렬 다중 뷰 검색**을 실행하고, ID 기반 중복 제거를 통해 결과를 병합합니다:

<table>
<tr>
<td width="50%">

**🔹 단순 쿼리**
- 단일 메모리 유닛을 통한 직접 사실 조회
- 최소 검색 깊이
- 빠른 응답 시간

</td>
<td width="50%">

**🔸 복잡한 쿼리**
- 여러 이벤트에 걸친 집계
- 확장된 검색 깊이
- 포괄적 커버리지

</td>
</tr>
</table>

**📈 결과**: 풀 컨텍스트 방법 대비 **30배 적은 토큰**으로 43.24%의 F1 점수 달성.

---

## 🚀 성능 하이라이트

### 📊 벤치마크 결과 (LoCoMo)

<details>
<summary><b>🔬 고성능 모델 (GPT-4.1-mini)</b></summary>

| 작업 유형 | SimpleMem F1 | Mem0 F1 | 개선 |
|:----------|:------------:|:-------:|:-----------:|
| **다중 홉** | 43.46% | 30.14% | **+43.8%** |
| **시간적** | 58.62% | 48.91% | **+19.9%** |
| **단일 홉** | 51.12% | 41.3% | **+23.8%** |

</details>

<details>
<summary><b>⚙️ 효율적 모델 (Qwen2.5-1.5B)</b></summary>

| 지표 | SimpleMem | Mem0 | 비고 |
|:-------|:---------:|:----:|:------|
| **평균 F1** | 25.23% | 23.77% | 99배 작은 모델로도 경쟁력 있음 |

</details>

---

## 📦 설치

### 📝 처음 사용자를 위한 참고사항

- **활성 환경에서 Python 3.10**을 사용하고 있는지 확인하세요 (전역 설치만으로는 부족합니다).
- 메모리 구축 또는 검색을 실행하기 전에 OpenAI 호환 API 키를 설정해야 합니다. 그렇지 않으면 초기화가 실패할 수 있습니다.
- OpenAI 이외의 공급자(예: Qwen 또는 Azure OpenAI)를 사용하는 경우, `config.py`에서 모델 이름과 `OPENAI_BASE_URL`을 모두 확인하세요.
- 대규모 대화 데이터셋의 경우, 병렬 처리를 활성화하면 메모리 구축 시간을 크게 단축할 수 있습니다.

### 📋 요구사항

- 🐍 Python 3.10
- 🔑 OpenAI 호환 API (OpenAI, Qwen, Azure OpenAI 등)

### 🛠️ 설치 방법

```bash
# 📥 저장소 클론
git clone https://github.com/aiming-lab/SimpleMem.git
cd SimpleMem

# 📦 의존성 설치
pip install -r requirements.txt

# ⚙️ API 설정 구성
cp config.py.example config.py
# config.py를 편집하여 API 키와 설정을 입력
```

### ⚙️ 설정 예시

```python
# config.py
OPENAI_API_KEY = "your-api-key"
OPENAI_BASE_URL = None  # 또는 Qwen/Azure의 커스텀 엔드포인트

LLM_MODEL = "gpt-4.1-mini"
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-0.6B"  # 최첨단 검색 성능
```

---

## ⚡ 빠른 시작

### 🧠 기본 워크플로우 이해

SimpleMem은 LLM 기반 에이전트의 장기 기억 시스템으로 작동합니다. 워크플로우는 세 가지 간단한 단계로 구성됩니다:

1. **정보 저장** – 대화 또는 사실이 처리되어 구조화된 원자적 기억으로 변환됩니다.
2. **기억 인덱싱** – 저장된 기억이 의미 임베딩과 구조화 메타데이터를 사용하여 정리됩니다.
3. **관련 기억 검색** – 쿼리 시 SimpleMem이 키워드가 아닌 의미에 기반하여 가장 관련성 높은 저장 정보를 검색합니다.

이 설계를 통해 LLM 에이전트는 컨텍스트를 유지하고, 과거 정보를 효율적으로 회상하며, 중복 이력의 재처리를 방지할 수 있습니다.

### 🎓 기본 사용법

```python
from main import SimpleMemSystem

# 🚀 시스템 초기화
system = SimpleMemSystem(clear_db=True)

# 💬 대화 추가 (단계 1: 의미적 구조화 압축)
system.add_dialogue("Alice", "Bob, let's meet at Starbucks tomorrow at 2pm", "2025-11-15T14:30:00")
system.add_dialogue("Bob", "Sure, I'll bring the market analysis report", "2025-11-15T14:31:00")

# ✅ 원자 인코딩 완료
system.finalize()

# 🔎 의도 인식 검색 쿼리 (단계 3: 의도 인식 검색 계획)
answer = system.ask("When and where will Alice and Bob meet?")
print(answer)
# 출력: "16 November 2025 at 2:00 PM at Starbucks"
```

---

### 🚄 고급: 병렬 처리

대규모 대화 처리 시 병렬 모드를 활성화하세요:

```python
system = SimpleMemSystem(
    clear_db=True,
    enable_parallel_processing=True,  # ⚡ 병렬 메모리 구축
    max_parallel_workers=8,
    enable_parallel_retrieval=True,   # 🔍 병렬 쿼리 실행
    max_retrieval_workers=4
)
```

> **💡 팁**: 병렬 처리로 배치 작업의 지연 시간을 크게 줄일 수 있습니다!

---

## ❓ 일반적인 문제 및 해결 방법

SimpleMem을 처음 설정하거나 실행할 때 문제가 발생하면 다음을 확인하세요:

### 1️⃣ API 키 미감지
- `config.py`에서 API 키가 올바르게 설정되었는지 확인
- OpenAI 호환 공급자(Qwen, Azure 등) 사용 시 `OPENAI_BASE_URL` 구성 확인
- 키 업데이트 후 Python 환경 재시작

### 2️⃣ Python 버전 불일치
- SimpleMem은 **Python 3.10**이 필요합니다
- 버전 확인:
  ```bash
  python --version
  ```

---

## 🔌 MCP 서버

SimpleMem은 Model Context Protocol (MCP)을 통해 **클라우드 호스팅 메모리 서비스**로 제공되며, Claude Desktop, Cursor 등의 AI 어시스턴트와 원활하게 통합됩니다.

**🌐 클라우드 서비스**: [mcp.simplemem.cloud](https://mcp.simplemem.cloud)

### 주요 기능

| 기능 | 설명 |
|---------|-------------|
| **Streamable HTTP** | MCP 2025-03-26 프로토콜, JSON-RPC 2.0 |
| **멀티 테넌트 격리** | 토큰 인증 기반 사용자별 데이터 테이블 |
| **하이브리드 검색** | 의미 검색 + 키워드 매칭 + 메타데이터 필터링 |
| **프로덕션 최적화** | OpenRouter 통합으로 빠른 응답 시간 |

### 빠른 설정

```json
{
  "mcpServers": {
    "simplemem": {
      "url": "https://mcp.simplemem.cloud/mcp",
      "headers": {
        "Authorization": "Bearer YOUR_TOKEN"
      }
    }
  }
}
```

> 📖 자세한 설정 안내와 자체 호스팅 가이드는 [MCP 문서](../../MCP/README.md)를 참조하세요

---

## 📊 평가

### 🧪 벤치마크 테스트 실행

```bash
# 🎯 전체 LoCoMo 벤치마크
python test_locomo10.py

# 📉 부분 평가 (5개 샘플)
python test_locomo10.py --num-samples 5

# 💾 커스텀 출력 파일
python test_locomo10.py --result-file my_results.json
```

---

### 🔬 논문 결과 재현

`config.py`의 정확한 설정을 사용하세요:
- **🚀 고성능**: GPT-4.1-mini, Qwen3-Plus
- **⚙️ 효율적**: Qwen2.5-1.5B, Qwen2.5-3B
- **🔍 임베딩**: Qwen3-Embedding-0.6B (1024차원)

---

## 📝 인용

연구에서 SimpleMem을 사용하신 경우, 다음을 인용해 주세요:

```bibtex
@article{simplemem2025,
  title={SimpleMem: Efficient Lifelong Memory for LLM Agents},
  author={Liu, Jiaqi and Su, Yaofeng and Xia, Peng and Zhou, Yiyang and Han, Siwei and  Zheng, Zeyu and Xie, Cihang and Ding, Mingyu and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2601.02553},
  year={2025},
  url={https://github.com/aiming-lab/SimpleMem}
}
```

---

## 📄 라이선스

이 프로젝트는 **MIT 라이선스** 하에 배포됩니다. 자세한 내용은 [LICENSE](../../LICENSE) 파일을 참조하세요.

---

## 🙏 감사의 말

다음 프로젝트와 팀에 감사드립니다:

- 🔍 **임베딩 모델**: [Qwen3-Embedding](https://github.com/QwenLM/Qwen) - 최첨단 검색 성능
- 🗄️ **벡터 데이터베이스**: [LanceDB](https://lancedb.com/) - 고성능 컬럼형 스토리지
- 📊 **벤치마크**: [LoCoMo](https://github.com/snap-research/locomo) - 장기 컨텍스트 메모리 평가 프레임워크
