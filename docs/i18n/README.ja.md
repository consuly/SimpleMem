<div align="center">

<img alt="simplemem_logo" src="https://github.com/user-attachments/assets/6ea54ad1-e007-442c-99d7-1174b10d1fec" width="450">

<div align="center">

## LLMエージェントのための効率的な生涯記憶

<small>意味的無損失圧縮により、長期記憶の保存・圧縮・検索を実現。Claude、Cursor、LM Studioなど多数のプラットフォームに対応。</small>

</div>

<p><b>MCPまたはPython統合をサポートするあらゆるAIプラットフォームで動作</b></p>

<table>
<tr>

<td align="center" width="100">
  <a href="https://www.anthropic.com/claude">
    <img src="https://cdn.simpleicons.org/claude/D97757" width="48" height="48" alt="Claude Desktop" />
  </a><br/>
  <sub>
    <a href="https://www.anthropic.com/claude"><b>Claude Desktop</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://cursor.com">
    <picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://cdn.simpleicons.org/cursor/FFFFFF">
      <img src="https://cdn.simpleicons.org/cursor/000000" width="48" height="48" alt="Cursor" />
    </picture>
  </a><br/>
  <sub>
    <a href="https://cursor.com"><b>Cursor</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://lmstudio.ai">
    <img src="https://github.com/lmstudio-ai.png?size=200" width="48" height="48" alt="LM Studio" />
  </a><br/>
  <sub>
    <a href="https://lmstudio.ai"><b>LM Studio</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://cherry-ai.com">
    <img src="https://github.com/CherryHQ.png?size=200" width="48" height="48" alt="Cherry Studio" />
  </a><br/>
  <sub>
    <a href="https://cherry-ai.com"><b>Cherry Studio</b></a>
  </sub>
</td>

<td align="center" width="100">
  <a href="https://pypi.org/project/simplemem/">
    <img src="https://cdn.simpleicons.org/pypi/3775A9" width="48" height="48" alt="PyPI" />
  </a><br/>
  <sub>
    <a href="https://pypi.org/project/simplemem/"><b>PyPI パッケージ</b></a>
  </sub>
</td>

<td align="center" width="100">
  <sub><b>+ あらゆる MCP<br/>クライアント</b></sub>
</td>

</tr>
</table>

<div align="center">

<br/>

[🇨🇳 中文](./README.zh-CN.md) •
[🇯🇵 **日本語**](./README.ja.md) •
[🇰🇷 한국어](./README.ko.md) •
[🇪🇸 Español](./README.es.md) •
[🇫🇷 Français](./README.fr.md) •
[🇩🇪 Deutsch](./README.de.md) •
[🇧🇷 Português](./README.pt-br.md)<br/>
[🇷🇺 Русский](./README.ru.md) •
[🇸🇦 العربية](./README.ar.md) •
[🇮🇹 Italiano](./README.it.md) •
[🇻🇳 Tiếng Việt](./README.vi.md) •
[🇹🇷 Türkçe](./README.tr.md)

<br/>

[![Project Page](https://img.shields.io/badge/🎬_インタラクティブデモ-ウェブサイトへ-FF6B6B?style=for-the-badge&labelColor=FF6B6B&color=4ECDC4&logoColor=white)](https://aiming-lab.github.io/SimpleMem-Page)

<p align="center">
  <a href="https://arxiv.org/abs/2601.02553"><img src="https://img.shields.io/badge/arXiv-2601.02553-b31b1b?style=flat&labelColor=555" alt="arXiv"></a>
  <a href="https://github.com/aiming-lab/SimpleMem"><img src="https://img.shields.io/badge/github-SimpleMem-181717?style=flat&labelColor=555&logo=github&logoColor=white" alt="GitHub"></a>
  <a href="../../LICENSE"><img src="https://img.shields.io/github/license/aiming-lab/SimpleMem?style=flat&label=license&labelColor=555&color=2EA44F" alt="License"></a>
  <a href="https://github.com/aiming-lab/SimpleMem/pulls"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen?style=flat&labelColor=555" alt="PRs Welcome"></a>
  <br/>
  <a href="https://pypi.org/project/simplemem/"><img src="https://img.shields.io/pypi/v/simplemem?style=flat&label=pypi&labelColor=555&color=3775A9&logo=pypi&logoColor=white" alt="PyPI"></a>
  <a href="https://pypi.org/project/simplemem/"><img src="https://img.shields.io/pypi/pyversions/simplemem?style=flat&label=python&labelColor=555&color=3775A9&logo=python&logoColor=white" alt="Python"></a>
  <a href="https://mcp.simplemem.cloud"><img src="https://img.shields.io/badge/MCP-mcp.simplemem.cloud-14B8A6?style=flat&labelColor=555" alt="MCP Server"></a>
  <a href="https://github.com/aiming-lab/SimpleMem"><img src="https://img.shields.io/badge/Claude_Skills-supported-FFB000?style=flat&labelColor=555" alt="Claude Skills"></a>
  <br/>
  <a href="https://discord.gg/KA2zC32M"><img src="https://img.shields.io/badge/Discord-チャットに参加-5865F2?style=flat&labelColor=555&logo=discord&logoColor=white" alt="Discord"></a>
  <a href="../../fig/wechat_logo3.JPG"><img src="https://img.shields.io/badge/WeChat-グループ-07C160?style=flat&labelColor=555&logo=wechat&logoColor=white" alt="WeChat"></a>
</p>

<br/>

[概要](#-概要) • [クイックスタート](#-クイックスタート) • [MCPサーバー](#-mcpサーバー) • [評価](#-評価) • [引用](#-引用)

</div>

</div>

<br/>

## 🔥 最新情報

- **[01/20/2026]** **SimpleMem が PyPI に公開されました！** 📦 `pip install simplemem` で直接インストールできます。[パッケージ使用ガイドを見る →](../PACKAGE_USAGE.md)
- **[01/19/2026]** **SimpleMem Skill にローカルメモリストレージを追加！** 💾 Claude Skills 内でのローカルメモリ保存・管理に対応しました。
- **[01/18/2026]** **SimpleMem が Claude Skills に対応！** 🚀 claude.ai で会話間の長期記憶を実現。[mcp.simplemem.cloud](https://mcp.simplemem.cloud) で登録し、トークンを設定してスキルをインポートしてください！
- **[01/14/2026]** **SimpleMem MCP サーバーが正式公開＆オープンソース化！** 🎉 クラウドメモリサービスが [mcp.simplemem.cloud](https://mcp.simplemem.cloud) で利用可能に。LM Studio、Cherry Studio、Cursor、Claude Desktop と **Streamable HTTP** MCP プロトコルで統合。[MCP ドキュメントを見る →](../../MCP/README.md)
- **[01/08/2026]** 🔥 [Discord](https://discord.gg/KA2zC32M) と [WeChat グループ](../../fig/wechat_logo3.JPG)に参加して、コラボレーションやアイデア交換をしましょう！
- **[01/05/2026]** SimpleMem の論文が [arXiv](https://arxiv.org/abs/2601.02553) で公開されました！

---

## 📑 目次

- [🌟 概要](#-概要)
- [🎯 主要貢献](#-主要貢献)
- [🚀 パフォーマンスハイライト](#-パフォーマンスハイライト)
- [📦 インストール](#-インストール)
- [⚡ クイックスタート](#-クイックスタート)
- [🔌 MCPサーバー](#-mcpサーバー)
- [📊 評価](#-評価)
- [📝 引用](#-引用)
- [📄 ライセンス](#-ライセンス)
- [🙏 謝辞](#-謝辞)

---

## 🌟 概要

<div align="center">
<img src="../../fig/Fig_tradeoff.png" alt="パフォーマンスと効率のトレードオフ" width="900"/>

*SimpleMem は最小限のトークンコスト（約550）で最高の F1 スコア（43.24%）を達成し、理想的な左上のポジションを占めています。*
</div>

**SimpleMem** は**意味的無損失圧縮**に基づく効率的なメモリフレームワークで、**LLMエージェントの効率的な長期記憶**という根本的な課題に取り組んでいます。冗長なコンテキストを受動的に蓄積したり、高コストの反復推論ループに依存する既存システムとは異なり、SimpleMem は3段階のパイプラインを通じて**情報密度**と**トークン利用率**を最大化します：

<table>
<tr>
<td width="33%" align="center">

### 🔍 ステージ 1
**意味的構造化圧縮**

非構造化インタラクションをコンパクトなマルチビューインデックス付きメモリユニットに蒸留

</td>
<td width="33%" align="center">

### 🗂️ ステージ 2
**オンライン意味合成**

セッション内プロセスで、関連コンテキストを統一された抽象表現に即座に統合し冗長性を排除

</td>
<td width="33%" align="center">

### 🎯 ステージ 3
**意図認識検索計画**

検索意図を推論し、検索範囲を動的に決定して効率的に正確なコンテキストを構築

</td>
</tr>
</table>

<div align="center">
<img src="../../fig/Fig_framework.png" alt="SimpleMem フレームワーク" width="900"/>

*SimpleMem アーキテクチャ：(1) 意味的構造化圧縮が低効用の対話をフィルタリングし、情報ウィンドウをコンパクトでコンテキスト非依存のメモリユニットに変換。(2) オンライン意味合成が書き込み時に関連フラグメントを統合し、コンパクトで一貫性のあるメモリトポロジーを維持。(3) 意図認識検索計画が検索意図を推論して検索範囲とクエリ形式を適応させ、並列マルチビュー検索とトークン効率の良いコンテキスト構築を実現。*
</div>

---

### 🏆 パフォーマンス比較

<div align="center">

**速度比較デモ**

<video src="https://github.com/aiming-lab/SimpleMem/raw/main/fig/simplemem-new.mp4" controls width="900"></video>

*SimpleMem vs. ベースライン：リアルタイム速度比較デモンストレーション*

</div>

<div align="center">

**LoCoMo-10 ベンチマーク結果（GPT-4.1-mini）**

| モデル | ⏱️ 構築時間 | 🔎 検索時間 | ⚡ 合計時間 | 🎯 平均 F1 |
|:------|:--------------------:|:-----------------:|:-------------:|:-------------:|
| A-Mem | 5140.5s | 796.7s | 5937.2s | 32.58% |
| LightMem | 97.8s | 577.1s | 675.9s | 24.63% |
| Mem0 | 1350.9s | 583.4s | 1934.3s | 34.20% |
| **SimpleMem** ⭐ | **92.6s** | **388.3s** | **480.9s** | **43.24%** |

</div>

> **💡 主な利点：**
> - 🏆 **最高 F1 スコア**：43.24%（Mem0 比 +26.4%、LightMem 比 +75.6%）
> - ⚡ **最速検索**：388.3s（LightMem より 32.7% 高速、Mem0 より 51.3% 高速）
> - 🚀 **最速エンドツーエンド**：合計処理時間 480.9s（A-Mem の 12.5 倍高速）

---

## 🎯 主要貢献

### 1️⃣ 意味的構造化圧縮

SimpleMem は LLM 生成プロセスに統合された**暗黙的意味密度ゲーティング**メカニズムを適用し、冗長なインタラクションコンテンツをフィルタリングします。システムは生の対話ストリームを**コンパクトなメモリユニット**（共参照が解決され絶対タイムスタンプが付与された自己完結型の事実）に再構成します。各ユニットは柔軟な検索のために3つの補完的表現でインデックスされます：

<div align="center">

| 🔍 レイヤー | 📊 タイプ | 🎯 目的 | 🛠️ 実装 |
|---------|---------|------------|-------------------|
| **意味的** | 密 | 概念的類似性 | ベクトル埋め込み（1024次元） |
| **語彙的** | 疎 | 正確な用語マッチング | BM25スタイルキーワードインデックス |
| **記号的** | メタデータ | 構造化フィルタリング | タイムスタンプ、エンティティ、人物 |

</div>

**✨ 変換例：**
```diff
- 入力：  "彼は明日午後2時にBobと会う"  [❌ 相対的、曖昧]
+ 出力： "AliceはStarbucksで2025-11-16T14:00:00にBobと会う"  [✅ 絶対的、原子的]
```

---

### 2️⃣ オンライン意味合成

非同期バックグラウンドメンテナンスに依存する従来のシステムとは異なり、SimpleMem は**書き込みフェーズ中にオンザフライで合成**を実行します。関連するメモリユニットは現在のセッションスコープ内でより高レベルの抽象表現に合成され、反復的または構造的に類似した経験を**即座にノイズ除去・圧縮**できます。

**✨ 合成例：**
```diff
- フラグメント 1: "ユーザーはコーヒーが欲しい"
- フラグメント 2: "ユーザーはオーツミルクを好む"
- フラグメント 3: "ユーザーはホットが好き"
+ 統合結果: "ユーザーはオーツミルク入りのホットコーヒーを好む"
```

この能動的な合成により、メモリトポロジーがコンパクトに保たれ、冗長なフラグメンテーションが回避されます。

---

### 3️⃣ 意図認識検索計画

固定深度の検索ではなく、SimpleMem は LLM の推論能力を活用して**包括的な検索計画**を生成します。クエリが与えられると、計画モジュールは**潜在的な検索意図**を推論し、検索範囲と深度を動的に決定します：

$$\{ q_{\text{sem}}, q_{\text{lex}}, q_{\text{sym}}, d \} \sim \mathcal{P}(q, H)$$

システムは意味的、語彙的、記号的インデックスにわたる**並列マルチビュー検索**を実行し、IDベースの重複排除で結果をマージします：

<table>
<tr>
<td width="50%">

**🔹 シンプルなクエリ**
- 単一メモリユニットによる直接的な事実検索
- 最小限の検索深度
- 高速レスポンス

</td>
<td width="50%">

**🔸 複雑なクエリ**
- 複数イベントにわたる集約
- 拡張された検索深度
- 包括的なカバレッジ

</td>
</tr>
</table>

**📈 結果**：フルコンテキスト手法と比較して **30倍少ないトークン** で 43.24% の F1 スコアを達成。

---

## 🚀 パフォーマンスハイライト

### 📊 ベンチマーク結果（LoCoMo）

<details>
<summary><b>🔬 高性能モデル（GPT-4.1-mini）</b></summary>

| タスクタイプ | SimpleMem F1 | Mem0 F1 | 改善 |
|:----------|:------------:|:-------:|:-----------:|
| **マルチホップ** | 43.46% | 30.14% | **+43.8%** |
| **時間的** | 58.62% | 48.91% | **+19.9%** |
| **シングルホップ** | 51.12% | 41.3% | **+23.8%** |

</details>

<details>
<summary><b>⚙️ 効率的モデル（Qwen2.5-1.5B）</b></summary>

| 指標 | SimpleMem | Mem0 | 備考 |
|:-------|:---------:|:----:|:------|
| **平均 F1** | 25.23% | 23.77% | 99倍小さいモデルでも競争力あり |

</details>

---

## 📦 インストール

### 📝 初めてのユーザーへの注意事項

- **アクティブな環境で Python 3.10** を使用していることを確認してください（グローバルインストールだけでは不十分です）。
- メモリ構築や検索を実行する前に、OpenAI 互換の API キーを設定する必要があります。設定しないと初期化が失敗する可能性があります。
- OpenAI 以外のプロバイダー（Qwen や Azure OpenAI など）を使用する場合、`config.py` のモデル名と `OPENAI_BASE_URL` の両方を確認してください。
- 大規模な対話データセットでは、並列処理を有効にすることでメモリ構築時間を大幅に短縮できます。

### 📋 要件

- 🐍 Python 3.10
- 🔑 OpenAI 互換 API（OpenAI、Qwen、Azure OpenAI など）

### 🛠️ セットアップ

```bash
# 📥 リポジトリをクローン
git clone https://github.com/aiming-lab/SimpleMem.git
cd SimpleMem

# 📦 依存関係をインストール
pip install -r requirements.txt

# ⚙️ API 設定を構成
cp config.py.example config.py
# config.py を編集してAPIキーと設定を入力
```

### ⚙️ 設定例

```python
# config.py
OPENAI_API_KEY = "your-api-key"
OPENAI_BASE_URL = None  # または Qwen/Azure のカスタムエンドポイント

LLM_MODEL = "gpt-4.1-mini"
EMBEDDING_MODEL = "Qwen/Qwen3-Embedding-0.6B"  # 最先端の検索性能
```

---

## ⚡ クイックスタート

### 🧠 基本ワークフローの理解

SimpleMem は LLM ベースのエージェントの長期記憶システムとして機能します。ワークフローは3つのシンプルなステップで構成されます：

1. **情報の保存** – 対話や事実が処理され、構造化された原子的メモリに変換されます。
2. **メモリのインデックス化** – 保存されたメモリが意味埋め込みと構造化メタデータを使用して整理されます。
3. **関連メモリの検索** – クエリ時に、SimpleMem がキーワードではなく意味に基づいて最も関連性の高い保存情報を検索します。

この設計により、LLM エージェントはコンテキストを維持し、過去の情報を効率的に想起し、冗長な履歴の再処理を回避できます。

### 🎓 基本的な使い方

```python
from main import SimpleMemSystem

# 🚀 システムを初期化
system = SimpleMemSystem(clear_db=True)

# 💬 対話を追加（ステージ 1：意味的構造化圧縮）
system.add_dialogue("Alice", "Bob, let's meet at Starbucks tomorrow at 2pm", "2025-11-15T14:30:00")
system.add_dialogue("Bob", "Sure, I'll bring the market analysis report", "2025-11-15T14:31:00")

# ✅ 原子エンコーディングを完了
system.finalize()

# 🔎 意図認識検索でクエリ（ステージ 3：意図認識検索計画）
answer = system.ask("When and where will Alice and Bob meet?")
print(answer)
# 出力: "16 November 2025 at 2:00 PM at Starbucks"
```

---

### 🚄 応用：並列処理

大規模な対話処理には、並列モードを有効にしてください：

```python
system = SimpleMemSystem(
    clear_db=True,
    enable_parallel_processing=True,  # ⚡ 並列メモリ構築
    max_parallel_workers=8,
    enable_parallel_retrieval=True,   # 🔍 並列クエリ実行
    max_retrieval_workers=4
)
```

> **💡 ヒント**：並列処理によりバッチ操作のレイテンシーが大幅に削減されます！

---

## ❓ よくある問題とトラブルシューティング

SimpleMem の初回セットアップや実行で問題が発生した場合、以下の一般的なケースを確認してください：

### 1️⃣ API キーが検出されない
- `config.py` で API キーが正しく設定されていることを確認
- OpenAI 互換プロバイダー（Qwen、Azure など）では、`OPENAI_BASE_URL` が正しく構成されていることを確認
- キー更新後に Python 環境を再起動

### 2️⃣ Python バージョンの不一致
- SimpleMem には **Python 3.10** が必要です
- バージョンを確認：
  ```bash
  python --version
  ```

---

## 🔌 MCPサーバー

SimpleMem は**クラウドホスト型メモリサービス**として、Model Context Protocol（MCP）を通じて提供され、Claude Desktop、Cursor などの AI アシスタントとのシームレスな統合を実現します。

**🌐 クラウドサービス**：[mcp.simplemem.cloud](https://mcp.simplemem.cloud)

### 主な機能

| 機能 | 説明 |
|---------|-------------|
| **Streamable HTTP** | MCP 2025-03-26 プロトコル（JSON-RPC 2.0） |
| **マルチテナント分離** | トークン認証によるユーザーごとのデータテーブル |
| **ハイブリッド検索** | 意味検索 + キーワードマッチング + メタデータフィルタリング |
| **本番環境最適化** | OpenRouter 統合による高速レスポンス |

### クイック構成

```json
{
  "mcpServers": {
    "simplemem": {
      "url": "https://mcp.simplemem.cloud/mcp",
      "headers": {
        "Authorization": "Bearer YOUR_TOKEN"
      }
    }
  }
}
```

> 📖 詳細なセットアップ手順とセルフホスティングガイドは [MCP ドキュメント](../../MCP/README.md) をご覧ください

---

## 📊 評価

### 🧪 ベンチマークテストの実行

```bash
# 🎯 完全な LoCoMo ベンチマーク
python test_locomo10.py

# 📉 サブセット評価（5サンプル）
python test_locomo10.py --num-samples 5

# 💾 カスタム出力ファイル
python test_locomo10.py --result-file my_results.json
```

---

### 🔬 論文結果の再現

`config.py` の正確な設定を使用してください：
- **🚀 高性能**：GPT-4.1-mini、Qwen3-Plus
- **⚙️ 効率的**：Qwen2.5-1.5B、Qwen2.5-3B
- **🔍 埋め込み**：Qwen3-Embedding-0.6B（1024次元）

---

## 📝 引用

研究で SimpleMem を使用される場合は、以下を引用してください：

```bibtex
@article{simplemem2025,
  title={SimpleMem: Efficient Lifelong Memory for LLM Agents},
  author={Liu, Jiaqi and Su, Yaofeng and Xia, Peng and Zhou, Yiyang and Han, Siwei and  Zheng, Zeyu and Xie, Cihang and Ding, Mingyu and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2601.02553},
  year={2025},
  url={https://github.com/aiming-lab/SimpleMem}
}
```

---

## 📄 ライセンス

このプロジェクトは **MIT ライセンス** の下で公開されています。詳細は [LICENSE](../../LICENSE) ファイルをご覧ください。

---

## 🙏 謝辞

以下のプロジェクトとチームに感謝いたします：

- 🔍 **埋め込みモデル**：[Qwen3-Embedding](https://github.com/QwenLM/Qwen) - 最先端の検索性能
- 🗄️ **ベクトルデータベース**：[LanceDB](https://lancedb.com/) - 高性能カラムナーストレージ
- 📊 **ベンチマーク**：[LoCoMo](https://github.com/snap-research/locomo) - 長コンテキストメモリ評価フレームワーク
